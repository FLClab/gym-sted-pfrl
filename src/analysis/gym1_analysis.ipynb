{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51f170f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0601b894",
   "metadata": {},
   "source": [
    "# Outline\n",
    "\n",
    "This notebook allows to analyse results from Gym1. There are two versions of the analysis: single processing or multi processing.\n",
    "\n",
    "Here are the available sections\n",
    "- [Analyse - Singleprocessing](#single)\n",
    "- [Analyse - Multiprocessing](#multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f876012a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import json\n",
    "import os\n",
    "import gym_sted\n",
    "import pfrl\n",
    "import torch\n",
    "import sys\n",
    "import pandas\n",
    "import random\n",
    "import pickle\n",
    "import logging\n",
    "import functools\n",
    "\n",
    "from tqdm.auto import trange, tqdm\n",
    "from matplotlib import pyplot\n",
    "from collections import defaultdict\n",
    "from skimage import io\n",
    "\n",
    "while \"../..\" in sys.path:\n",
    "    sys.path.remove(\"../..\")\n",
    "sys.path.insert(0, \"../..\")\n",
    "from src import models, WrapPyTorch\n",
    "\n",
    "from gym_sted.envs.sted_env import action_spaces, scales_dict, bounds_dict\n",
    "\n",
    "# Defines constants\n",
    "PATH = \"../../data\"\n",
    "PHY_REACTS = {\n",
    "    \"low-bleach\" : gym_sted.defaults.FLUO[\"phy_react\"],\n",
    "    \"mid-bleach\" : {488: 0.5e-7 + 3 * 0.25e-7, 575: 50.0e-11 + 3 * 25.0e-11},\n",
    "    \"high-bleach\" : {488: 0.5e-7 + 10 * 0.25e-7, 575: 50.0e-11 + 10 * 25.0e-11},\n",
    "}\n",
    "OBJS_YLIM = {\n",
    "    \"Resolution\" : (0, 250),\n",
    "    \"Bleach\" : (0, 1),\n",
    "    \"SNR\" : (0, 2)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c5564f",
   "metadata": {},
   "source": [
    "## Utilitaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab171c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(x, kernel_size):\n",
    "    \"\"\"\n",
    "    Computes a sliding window average over the specified data\n",
    "    \n",
    "    :param x: A `numpy.ndarray` of the data\n",
    "    :param kernel_size: An `int` of the size of the sliding window\n",
    "    \n",
    "    :returns : A `numpy.ndarray` of the averaged data\n",
    "    \"\"\"\n",
    "    if kernel_size < 2:\n",
    "        return x\n",
    "    window = windows.boxcar(kernel_size)\n",
    "    window = window / window.sum()\n",
    "    _x = numpy.pad(x, (kernel_size, kernel_size), mode=\"edge\")\n",
    "    return numpy.convolve(_x, window, mode=\"same\")[kernel_size : -kernel_size]\n",
    "\n",
    "def plot_score(df, x, y, shade_keys=None, smooth=1):\n",
    "    \"\"\"\n",
    "    Plots the scores from a `pandas.DataFrame` using the provided \n",
    "    key\n",
    "    \n",
    "    :param df: A `pandas.DataFrame`\n",
    "    :param key: A `str` of the desired key\n",
    "    :param shade_keys: A `list` of keys to use as shade\n",
    "    :param xlabel:\n",
    "    \n",
    "    :returns : A `matplotlib.Figure` of the created plot\n",
    "               A `matplotlib.Axes` of the create plot\n",
    "    \"\"\"\n",
    "    fig, ax = pyplot.subplots(figsize=(3,3))\n",
    "    ax.plot(df[x], sliding_window(df[y], smooth))\n",
    "    if isinstance(shade_keys, (tuple, list)):\n",
    "        ax.fill_between(\n",
    "            df[x], \n",
    "            sliding_window(df[y] - df[shade_keys[0]], smooth), \n",
    "            sliding_window(df[y] + df[shade_keys[1]], smooth), \n",
    "            alpha=0.3\n",
    "        )\n",
    "    elif isinstance(shade_keys, str):\n",
    "        ax.fill_between(\n",
    "            df[x], \n",
    "            sliding_window(df[y] - df[shade_keys], smooth), \n",
    "            sliding_window(df[y] + df[shade_keys], smooth), \n",
    "            alpha=0.3\n",
    "        )\n",
    "    ax.set(\n",
    "        xlabel=x, ylabel=y\n",
    "    )\n",
    "    return fig, ax\n",
    "\n",
    "def savefig(fig, ax, savepath, extension=\"pdf\", save_white=False):\n",
    "    \"\"\"\n",
    "    Utilitary function allowing to save the figure to \n",
    "    the savepath\n",
    "    \n",
    "    :param fig: A `matplotlib.Figure`\n",
    "    :param ax: A `matplotlib.Axes`  \n",
    "    :param savepath: A `str` of the filename\n",
    "    :param extension: A `str` of the extension of the file\n",
    "    :param save_white: A `bool` wheter to save the figure in white version \n",
    "                       as well\n",
    "    \"\"\"\n",
    "    fig.savefig(f\"{savepath}.{extension}\", bbox_inches=\"tight\", transparent=True)\n",
    "    if save_white:\n",
    "        change_figax_color(fig, ax)\n",
    "        fig.savefig(f\"{savepath}_white.{extension}\", bbox_inches=\"tight\", transparent=True)\n",
    "        \n",
    "def change_figax_color(fig, ax):\n",
    "    \"\"\"\n",
    "    Utilitary function allowing to change the figure and \n",
    "    ax color from black to white\n",
    "    \n",
    "    :param fig: A `matplotlib.Figure`\n",
    "    :param ax: A `matplotlib.Axes`    \n",
    "    \"\"\"\n",
    "    def _change_ax(ax):\n",
    "        ax.set_facecolor(\"none\")\n",
    "        for child in ax.get_children():\n",
    "            if isinstance(child, matplotlib.spines.Spine):\n",
    "                child.set_color('white')      \n",
    "        ax.tick_params(axis='x', colors='white')\n",
    "        ax.tick_params(axis='y', colors='white')\n",
    "        ax.yaxis.label.set_color('white')\n",
    "        ax.xaxis.label.set_color('white')\n",
    "        ax.title.set_color(\"white\")\n",
    "        \n",
    "        # For line plots\n",
    "        for line in ax.get_lines():\n",
    "            if line.get_color() in [\"#000000\", \"000000\", \"black\"]:\n",
    "                line.set_color(\"white\")    \n",
    "\n",
    "        # For scatter plots\n",
    "        for collection in ax.collections:\n",
    "            new_colors = [\"white\" if matplotlib.colors.to_hex(c) == \"#000000\" else c \n",
    "                             for c in collection.get_facecolors()]\n",
    "            collection.set_facecolors(new_colors)\n",
    "            new_colors = [\"white\" if matplotlib.colors.to_hex(c) == \"#000000\" else c \n",
    "                             for c in collection.get_edgecolors()]   \n",
    "            collection.set_edgecolors(new_colors)\n",
    "\n",
    "        # For hist plots\n",
    "        for patch in ax.patches:\n",
    "            c = patch.get_facecolor()\n",
    "            if matplotlib.colors.to_hex(c) == \"#000000\":\n",
    "                patch.set_color(\"white\")        \n",
    "        \n",
    "    # Change figure background\n",
    "    fig.patch.set_facecolor(\"none\")\n",
    "    \n",
    "    # Changes colorbars if any\n",
    "    for ax in fig.axes:\n",
    "        _change_ax(ax.axes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753d07a5",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4138d3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_avg_reward(episode_stats, **kwargs):\n",
    "    \"\"\"\n",
    "    Plots the average cummulated reward for all repetitions \n",
    "    \n",
    "    :param episode_stats: A `list` of all episodes statistics\n",
    "    \n",
    "    :returns : A `matplotlib.Figure`\n",
    "               A `matplotlib.Axes`\n",
    "    \"\"\"\n",
    "    values = [sum([info[\"reward\"] for info in infos]) for infos in episode_stats]\n",
    "    fig, ax = pyplot.subplots(figsize=(3,3))\n",
    "    ax.violinplot(values)\n",
    "    ax.set(\n",
    "        title=\"Average reward\", **kwargs\n",
    "    )\n",
    "    return fig, ax\n",
    "\n",
    "def plot_objs_evolution(episode_stats, obj_names=[\"Resolution\", \"Bleach\", \"SNR\"]):\n",
    "    \"\"\"\n",
    "    Plots the evolution of each objectives during an episode. The evolution \n",
    "    is averaged across the repetitions\n",
    "    \n",
    "    :param episode_stats: A `list` of all episodes statistics\n",
    "    :param obj_names: A `list` of corresponding objective names\n",
    "    \n",
    "    :returns : A `dict` of all the created figure\n",
    "    \"\"\"\n",
    "    values = [[info[\"mo_objs\"] for info in infos] for infos in episode_stats]\n",
    "    \n",
    "    # Average over repetitions\n",
    "    means = numpy.mean(values, axis=0)\n",
    "    stds = numpy.std(values, axis=0)\n",
    "    \n",
    "    figaxes = {}\n",
    "    for i, (key, mean, std) in enumerate(zip(obj_names, means.T, stds.T)):    \n",
    "        fig, ax = pyplot.subplots(figsize=(3,3))\n",
    "        x = numpy.arange(len(mean))\n",
    "        ax.plot(x, mean, label=key)\n",
    "        ax.fill_between(x, mean - std, mean + std, alpha=0.3)        \n",
    "        ax.set(\n",
    "            ylim=OBJS_YLIM[key], ylabel=key\n",
    "        )\n",
    "        figaxes[key] = (fig, ax)\n",
    "    return figaxes\n",
    "\n",
    "def plot_actions_evolution(episode_stats, normalize=True, action_names=[\"p_sted\", \"p_ex\", \"pdt\"]):\n",
    "    \"\"\"\n",
    "    Plots the evolution of each actions during an episode. The evolution \n",
    "    is averaged across the repetitions\n",
    "    \n",
    "    :param episode_stats: A `list` of all episodes statistics\n",
    "    :param obj_names: A `list` of corresponding objective names\n",
    "    \n",
    "    :returns : A `dict` of all the created figure    \n",
    "    \"\"\"\n",
    "    values = [[info[\"action\"] for info in infos] for infos in episode_stats]\n",
    "    \n",
    "    # Average over repetitions\n",
    "    means = numpy.mean(values, axis=0)\n",
    "    stds = numpy.std(values, axis=0)    \n",
    "    \n",
    "    figaxes = {}\n",
    "    for i, (key, mean, std) in enumerate(zip(action_names, means.T, stds.T)):    \n",
    "        fig, ax = pyplot.subplots(figsize=(3,3))\n",
    "        x = numpy.arange(len(mean))\n",
    "        \n",
    "        if normalize:\n",
    "            mean = (mean - action_spaces[key][\"low\"]) / (action_spaces[key][\"high\"] - action_spaces[key][\"low\"])\n",
    "            std = (std - action_spaces[key][\"low\"]) / (action_spaces[key][\"high\"] - action_spaces[key][\"low\"])\n",
    "            \n",
    "        ax.plot(x, mean, label=key)\n",
    "        ax.fill_between(x, mean - std, mean + std, alpha=0.3)        \n",
    "        ax.set(\n",
    "            ylabel=key, ylim=(0, 1) if normalize else None\n",
    "        )\n",
    "        figaxes[key] = (fig, ax)\n",
    "    return figaxes    \n",
    "    \n",
    "def show_acquire_images(episode_stats, num_examples=3):\n",
    "    \"\"\"\n",
    "    Shows example of acquired images across an episode\n",
    "    \n",
    "    :param episode_stats: A `list` of all episodes statistics\n",
    "    :param num_examples: An `int` of the number of examples to retreive\n",
    "    \n",
    "    :returns : A `list` of examples where each example contains {conf1, sted_image, conf2}\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    choices = numpy.random.choice(len(episode_stats), size=min(len(episode_stats), num_examples), replace=False)\n",
    "    for choice in choices:\n",
    "        conf1_images = numpy.concatenate([info[\"conf1\"] for info in episode_stats[choice]], axis=1)\n",
    "        sted_images = numpy.concatenate([info[\"sted_image\"] for info in episode_stats[choice]], axis=1)   \n",
    "        conf2_images = numpy.concatenate([info[\"conf2\"] for info in episode_stats[choice]], axis=1)\n",
    "        out.append({\n",
    "            \"conf1\" : conf1_images,\n",
    "            \"sted_image\" : sted_images, \n",
    "            \"conf2\" : conf2_images\n",
    "        })\n",
    "    return out\n",
    "\n",
    "def plot_avg_action(episode_stats):\n",
    "    values = [stats[\"info\"][0][\"action\"] for stats in episode_stats]\n",
    "    values = numpy.array(values)\n",
    "    \n",
    "    fig, ax = pyplot.subplots(figsize=(3,3))\n",
    "    for i, (key, value) in enumerate(zip(env.actions, values.T)):    \n",
    "        value = (value - action_spaces[key][\"low\"]) / (action_spaces[key][\"high\"] - action_spaces[key][\"low\"])\n",
    "        ax.violinplot(value, positions=[i])\n",
    "    ax.set(\n",
    "        ylim=(0, 1), title=\"Actions\",\n",
    "        xticks=(numpy.arange(values.shape[-1])), xticklabels=(env.actions)        \n",
    "    )\n",
    "    return fig, ax\n",
    "\n",
    "def plot_avg_multiaction(episode_stats):\n",
    "    values = [numpy.array([step[\"action\"] for step in stats[\"info\"]]) for stats in episode_stats]\n",
    "\n",
    "    out = {\"imaging-action\" : []}\n",
    "    for i, key in enumerate(env.actions):\n",
    "        fig, ax = pyplot.subplots(figsize=(3,3))\n",
    "        for value in values:\n",
    "            value = (value[:, i] - action_spaces[key][\"low\"]) / (action_spaces[key][\"high\"] - action_spaces[key][\"low\"])\n",
    "            ax.plot(value, alpha=0.3, color=\"black\", label=key)\n",
    "            ax.scatter(len(value) - 1, value[-1], marker=\"*\", color=\"black\")\n",
    "        ax.set(\n",
    "            ylim=(0, 1), title=\"Imaging action\",\n",
    "            xlabel=\"Steps\", ylabel=key\n",
    "        )\n",
    "        out[\"imaging-action\"].append((fig, ax))\n",
    "    \n",
    "    fig, ax = pyplot.subplots(figsize=(3,3))\n",
    "    for value in values:\n",
    "        value = numpy.clip(value[:, -1].astype(int) - 1, 0, 2)\n",
    "        index = numpy.argmax(value == 1)\n",
    "        where = value == 1\n",
    "        where[index] = False\n",
    "        value[where] = 0\n",
    "        value[-1] = 2\n",
    "        ax.plot(value, color=\"black\", alpha=0.3)\n",
    "    ax.set(\n",
    "        ylim=(0, 2), title=\"Main action\",\n",
    "        xlabel=\"Steps\"\n",
    "    )\n",
    "    out[\"main-action\"] = (fig, ax)    \n",
    "    \n",
    "    return out\n",
    "\n",
    "def plot_last_image(episode_stats):\n",
    "    \"\"\"\n",
    "    Plots the last acquired image across all episodes\n",
    "    \"\"\"\n",
    "    out = {}\n",
    "    \n",
    "    images = [stats[\"info\"][-1][\"conf1\"] for stats in episode_stats]\n",
    "    fig, axes = pyplot.subplots(3, 3, figsize=(10,10), sharex=True, sharey=True)\n",
    "    for ax, image in zip(axes.ravel(), images):\n",
    "        ax.imshow(image, cmap=\"hot\", vmin=0, vmax=1000)\n",
    "    out[\"conf1\"] = (fig, axes)\n",
    "        \n",
    "    images = [stats[\"info\"][-1][\"sted_image\"] for stats in episode_stats]\n",
    "    fig, axes = pyplot.subplots(3, 3, figsize=(10,10), sharex=True, sharey=True)\n",
    "    vmax = max([img.max() for img in images])\n",
    "    for ax, image in zip(axes.ravel(), images):\n",
    "        ax.imshow(image, cmap=\"hot\", vmin=0, vmax=vmax) \n",
    "    out[\"sted_image\"] = (fig, axes)        \n",
    "        \n",
    "    images = [stats[\"info\"][-1][\"conf2\"] for stats in episode_stats]\n",
    "    fig, axes = pyplot.subplots(3, 3, figsize=(10,10), sharex=True, sharey=True)\n",
    "    for ax, image in zip(axes.ravel(), images):\n",
    "        ax.imshow(image, cmap=\"hot\", vmin=0, vmax=1000)                \n",
    "    out[\"conf2\"] = (fig, axes)            \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd65069",
   "metadata": {},
   "source": [
    "<a id=\"single\"></a>\n",
    "# Analyse Results - Single Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4cccb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_name = \"20210901-092428_f62b76d6\"\n",
    "os.makedirs(os.path.join(PATH, model_name, \"panels\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(PATH, model_name, \"eval\"), exist_ok=True)\n",
    "\n",
    "args = json.load(open(os.path.join(PATH, model_name, \"args.txt\"), \"r\"))\n",
    "print(args)\n",
    "def make_env(test):\n",
    "    # Use different random seeds for train and test envs\n",
    "    env_seed = 42\n",
    "    env = gym.make(args[\"env\"])\n",
    "    # Use different random seeds for train and test envs\n",
    "    env.seed(env_seed)\n",
    "    # Converts the openAI Gym to PyTorch tensor shape\n",
    "    env = WrapPyTorch(env)\n",
    "    # Normalize the action space\n",
    "    env = pfrl.wrappers.NormalizeActionSpace(env)\n",
    "    return env\n",
    "\n",
    "env = make_env(True)\n",
    "timestep_limit = env.spec.max_episode_steps\n",
    "obs_space = env.observation_space\n",
    "action_space = env.action_space\n",
    "\n",
    "policy = models.Policy2(action_size=action_space.shape[0], obs_space=obs_space)\n",
    "vf = models.ValueFunction2(obs_space=obs_space)\n",
    "model = pfrl.nn.Branched(policy, vf)\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(), lr=args[\"lr\"])\n",
    "\n",
    "agent = pfrl.agents.PPO(\n",
    "    model,\n",
    "    opt,\n",
    "    gpu=None,\n",
    "    minibatch_size=args[\"batchsize\"],\n",
    "    max_grad_norm=1.0,\n",
    "    update_interval=100\n",
    ")\n",
    "agent.load(os.path.join(PATH, model_name, \"best\"))\n",
    "print(agent)\n",
    "\n",
    "df = pandas.read_csv(os.path.join(PATH, model_name, \"scores.txt\"), sep=\"\\t\")\n",
    "display(df.head())\n",
    "\n",
    "smoothing_factor = 0\n",
    "fig, ax = plot_score(df, \"steps\", \"mean\", shade_keys=\"stdev\", smooth=smoothing_factor)\n",
    "savefig(fig, ax, os.path.join(PATH, model_name, \"panels\", \"mean_reward\"), save_white=True)\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba5f791",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_count = 10\n",
    "render, done = False, False\n",
    "\n",
    "episode_stats = defaultdict(list)\n",
    "for key, phy_react in PHY_REACTS.items():\n",
    "    with agent.eval_mode():\n",
    "        for i in trange(episode_count, desc=key, leave=False):\n",
    "            observation = env.reset()\n",
    "\n",
    "            # Sets the microscope bleach constant to default values\n",
    "            env.microscope.fluo.phy_react = phy_react\n",
    "    #         env.synapse_generator = gym_sted.utils.SynapseGenerator(mode=\"rand\", seed=None, molecules=1)\n",
    "    #         env.microscope.fluo.phy_react = {\n",
    "    #             488: 0.5e-7 + 3 * 0.25e-7,\n",
    "    #             575: 50.0e-11 + 3 * 25.0e-11\n",
    "    #         }\n",
    "\n",
    "            timestep, episode_len, cum_rewards = 0, 0, 0\n",
    "            max_episode_len = env.spec.max_episode_steps\n",
    "\n",
    "            stats = [] \n",
    "            while True:\n",
    "                action = agent.act(observation)\n",
    "\n",
    "                observation, reward, done, info = env.step(action)\n",
    "                reset = done or episode_len == max_episode_len or info.get(\"needs_reset\", False)\n",
    "                agent.observe(observation, reward, done, reset)\n",
    "\n",
    "                stats.append(info)\n",
    "\n",
    "                if render:\n",
    "                    env.render(info)\n",
    "                if done:\n",
    "                    break\n",
    "\n",
    "                episode_len += 1\n",
    "\n",
    "            episode_stats[key].append(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acb27ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "pickle.dump(episode_stats, open(os.path.join(PATH, model_name, \"eval\", \"stats.pkl\"), \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001f6a8b",
   "metadata": {},
   "source": [
    "## Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1d0125",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for bleach in PHY_REACTS.keys():\n",
    "\n",
    "    fig, ax = plot_avg_reward(episode_stats[bleach])\n",
    "    savefig(fig, ax, os.path.join(PATH, model_name, \"panels\", f\"{bleach}_avg_reward\"), save_white=True)\n",
    "\n",
    "    # fig, ax = plot_avg_rewards(episode_stats)\n",
    "    # savefig(fig, ax, os.path.join(PATH, model_name, \"panels\", \"avg_rewards\"), save_white=True)\n",
    "\n",
    "    # fig, ax = plot_avg_action(episode_stats)\n",
    "    # savefig(fig, ax, os.path.join(PATH, model_name, \"panels\", \"avg_action\"), save_white=True)\n",
    "\n",
    "    figaxes = plot_avg_multiaction(episode_stats[bleach])\n",
    "    for key, figaxes in figaxes.items():\n",
    "        if isinstance(figaxes, tuple):\n",
    "            fig, ax = figaxes\n",
    "            savefig(fig, ax, os.path.join(PATH, model_name, \"panels\", f\"{bleach}_avg_multiaction_{key}\"), save_white=True)\n",
    "        else:\n",
    "            for action_name, (fig, ax) in zip(env.actions, figaxes):\n",
    "                savefig(fig, ax, os.path.join(PATH, model_name, \"panels\", f\"{bleach}_avg_multiaction_{key}_{action_name}\"), save_white=True)            \n",
    "\n",
    "    figaxes = plot_last_image(episode_stats[bleach])\n",
    "    for key, figaxes in figaxes.items():\n",
    "        if isinstance(figaxes, tuple):\n",
    "            fig, ax = figaxes\n",
    "            savefig(fig, ax, os.path.join(PATH, model_name, \"panels\", f\"{bleach}_last-images_{key}\"), save_white=True)\n",
    "        else:\n",
    "            for action_name, (fig, ax) in zip(env.actions, figaxes):\n",
    "                savefig(fig, ax, os.path.join(PATH, model_name, \"panels\", f\"{bleach}_last-images_{key}_{action_name}\"), save_white=True)            \n",
    "\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8c3c32",
   "metadata": {},
   "source": [
    "<a id=\"multi\"></a>\n",
    "# Analyse results - Multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49db0ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _batch_run_episodes_record(\n",
    "    env,\n",
    "    agent,\n",
    "    n_steps,\n",
    "    n_episodes,\n",
    "    max_episode_len=None,\n",
    "    logger=None,\n",
    "):\n",
    "    \"\"\"Run multiple episodes and return returns in a batch manner.\"\"\"\n",
    "    assert (n_steps is None) != (n_episodes is None)\n",
    "\n",
    "    logger = logger or logging.getLogger(__name__)\n",
    "    num_envs = env.num_envs\n",
    "    episode_returns = dict()\n",
    "    episode_lengths = dict()\n",
    "    episode_infos = dict()\n",
    "    episode_indices = numpy.zeros(num_envs, dtype=\"i\")\n",
    "    episode_idx = 0\n",
    "    for i in range(num_envs):\n",
    "        episode_indices[i] = episode_idx\n",
    "        episode_idx += 1\n",
    "    episode_r = numpy.zeros(num_envs, dtype=numpy.float64)\n",
    "    episode_len = numpy.zeros(num_envs, dtype=\"i\")\n",
    "    episode_info = [[] for _ in range(num_envs)]\n",
    "\n",
    "    obss = env.reset()\n",
    "    rs = numpy.zeros(num_envs, dtype=\"f\")\n",
    "\n",
    "    termination_conditions = False\n",
    "    timestep = 0\n",
    "    while True:\n",
    "        \n",
    "        # a_t\n",
    "        actions = agent.batch_act(obss)\n",
    "        timestep += 1\n",
    "        # o_{t+1}, r_{t+1}\n",
    "        obss, rs, dones, infos = env.step(actions)\n",
    "        episode_r += rs\n",
    "        episode_len += 1\n",
    "        for i, info in enumerate(infos):\n",
    "            episode_info[i].append(info)\n",
    "\n",
    "        # Compute mask for done and reset\n",
    "        if max_episode_len is None:\n",
    "            resets = numpy.zeros(num_envs, dtype=bool)\n",
    "        else:\n",
    "            resets = episode_len == max_episode_len\n",
    "        resets = numpy.logical_or(\n",
    "            resets, [info.get(\"needs_reset\", False) for info in infos]\n",
    "        )\n",
    "\n",
    "        # Make mask. 0 if done/reset, 1 if pass\n",
    "        end = numpy.logical_or(resets, dones)\n",
    "        not_end = numpy.logical_not(end)\n",
    "\n",
    "        for index in range(len(end)):\n",
    "            if end[index]:\n",
    "                episode_returns[episode_indices[index]] = episode_r[index]\n",
    "                episode_lengths[episode_indices[index]] = episode_len[index]\n",
    "                episode_infos[episode_indices[index]] = episode_info[index]\n",
    "                # Give the new episode an a new episode index\n",
    "                episode_indices[index] = episode_idx\n",
    "                episode_idx += 1\n",
    "\n",
    "        # Resets done episode\n",
    "        episode_r[end] = 0\n",
    "        episode_len[end] = 0\n",
    "        for index in range(len(end)):\n",
    "            if end[index]:\n",
    "                episode_info[index] = []\n",
    "\n",
    "        # find first unfinished episode\n",
    "        first_unfinished_episode = 0\n",
    "        while first_unfinished_episode in episode_returns:\n",
    "            first_unfinished_episode += 1\n",
    "\n",
    "        # Check for termination conditions\n",
    "        eval_episode_returns = []\n",
    "        eval_episode_lens = []\n",
    "        eval_episode_infos = []\n",
    "        if n_steps is not None:\n",
    "            total_time = 0\n",
    "            for index in range(first_unfinished_episode):\n",
    "                total_time += episode_lengths[index]\n",
    "                # If you will run over allocated steps, quit\n",
    "                if total_time > n_steps:\n",
    "                    break\n",
    "                else:\n",
    "                    eval_episode_returns.append(episode_returns[index])\n",
    "                    eval_episode_lens.append(episode_lengths[index])\n",
    "                    eval_episode_infos.append(episode_infos[index])\n",
    "            termination_conditions = total_time >= n_steps\n",
    "            if not termination_conditions:\n",
    "                unfinished_index = numpy.where(\n",
    "                    episode_indices == first_unfinished_episode\n",
    "                )[0]\n",
    "                if total_time + episode_len[unfinished_index] >= n_steps:\n",
    "                    termination_conditions = True\n",
    "                    if first_unfinished_episode == 0:\n",
    "                        eval_episode_returns.append(episode_r[unfinished_index])\n",
    "                        eval_episode_lens.append(episode_len[unfinished_index])\n",
    "                        eval_episode_infos.append(episode_infos[index])\n",
    "        else:\n",
    "            termination_conditions = first_unfinished_episode >= n_episodes\n",
    "            if termination_conditions:\n",
    "                # Get the first n completed episodes\n",
    "                for index in range(n_episodes):\n",
    "                    eval_episode_returns.append(episode_returns[index])\n",
    "                    eval_episode_lens.append(episode_lengths[index])\n",
    "                    eval_episode_infos.append(episode_infos[index])                    \n",
    "\n",
    "        if termination_conditions:\n",
    "            # If this is the last step, make sure the agent observes reset=True\n",
    "            resets.fill(True)\n",
    "\n",
    "        # Agent observes the consequences.\n",
    "        agent.batch_observe(obss, rs, dones, resets)\n",
    "\n",
    "        if termination_conditions:\n",
    "            break\n",
    "        else:\n",
    "            obss = env.reset(not_end)\n",
    "\n",
    "    for i, (epi_len, epi_ret) in enumerate(\n",
    "        zip(eval_episode_lens, eval_episode_returns)\n",
    "    ):\n",
    "        logger.info(\"evaluation episode %s length: %s R: %s\", i, epi_len, epi_ret)\n",
    "    scores = [float(r) for r in eval_episode_returns]\n",
    "    lengths = [float(ln) for ln in eval_episode_lens]\n",
    "    infos = [info for info in eval_episode_infos]\n",
    "    return scores, lengths, infos\n",
    "\n",
    "\n",
    "def batch_run_evaluation_episodes_record_actions(\n",
    "    env,\n",
    "    agent,\n",
    "    n_steps,\n",
    "    n_episodes,\n",
    "    max_episode_len=None,\n",
    "    logger=None,\n",
    "):\n",
    "    \"\"\"Run multiple evaluation episodes and return returns in a batch manner.\n",
    "\n",
    "    Args:\n",
    "        env (VectorEnv): Environment used for evaluation.\n",
    "        agent (Agent): Agent to evaluate.\n",
    "        n_steps (int): Number of total timesteps to evaluate the agent.\n",
    "        n_episodes (int): Number of evaluation runs.\n",
    "        max_episode_len (int or None): If specified, episodes\n",
    "            longer than this value will be truncated.\n",
    "        logger (Logger or None): If specified, the given Logger\n",
    "            object will be used for logging results. If not\n",
    "            specified, the default logger of this module will\n",
    "            be used.\n",
    "\n",
    "    Returns:\n",
    "        List of returns of evaluation runs.\n",
    "    \"\"\"\n",
    "    with agent.eval_mode():\n",
    "        return _batch_run_episodes_record(\n",
    "            env=env,\n",
    "            agent=agent,\n",
    "            n_steps=n_steps,\n",
    "            n_episodes=n_episodes,\n",
    "            max_episode_len=max_episode_len,\n",
    "            logger=logger,\n",
    "        )\n",
    "    \n",
    "model_name = \"20210901-092428_f62b76d6\"\n",
    "os.makedirs(os.path.join(PATH, model_name, \"panels\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(PATH, model_name, \"eval\"), exist_ok=True)\n",
    "\n",
    "args = json.load(open(os.path.join(PATH, model_name, \"args.txt\"), \"r\"))\n",
    "args[\"env\"] = \"gym_sted:MOSTEDRankingWithArticulation-hard-v4\"\n",
    "NUM_ENVS = 5\n",
    "\n",
    "process_seeds = numpy.arange(NUM_ENVS) + 42\n",
    "def make_env(idx, test, **kwargs):\n",
    "    # Use different random seeds for train and test envs\n",
    "    process_seed = int(process_seeds[idx])\n",
    "    env_seed = 2 ** 32 - 1 - process_seed if test else process_seed\n",
    "    env = gym.make(args[\"env\"])\n",
    "    # Use different random seeds for train and test envs\n",
    "    env.seed(env_seed)\n",
    "    # Converts the openAI Gym to PyTorch tensor shape\n",
    "    env = WrapPyTorch(env)\n",
    "    # Normalize the action space\n",
    "    env = pfrl.wrappers.NormalizeActionSpace(env)\n",
    "    \n",
    "    if \"phy_react\" in kwargs:\n",
    "        env.microscope.fluo.phy_react = kwargs.get(\"phy_react\")\n",
    "    return env\n",
    "\n",
    "def make_batch_env(test, **kwargs):\n",
    "    vec_env = pfrl.envs.MultiprocessVectorEnv(\n",
    "        [\n",
    "            functools.partial(make_env, idx, test, **kwargs)\n",
    "            for idx, env in enumerate(range(NUM_ENVS))\n",
    "        ]\n",
    "    )\n",
    "    # vec_env = pfrl.wrappers.VectorFrameStack(vec_env, 4)\n",
    "    return vec_env\n",
    "\n",
    "env = make_env(0, True)\n",
    "timestep_limit = env.spec.max_episode_steps\n",
    "obs_space = env.observation_space\n",
    "action_space = env.action_space\n",
    "\n",
    "# Creates the agent \n",
    "policy = models.PolicyWithSideAction(action_size=action_space.shape[0], obs_space=obs_space)\n",
    "vf = models.ValueFunction2(obs_space=obs_space)\n",
    "model = pfrl.nn.Branched(policy, vf)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=args[\"lr\"])\n",
    "agent = pfrl.agents.PPO(\n",
    "    model,\n",
    "    opt,\n",
    "    gpu=None,\n",
    "    minibatch_size=args[\"batchsize\"],\n",
    "    max_grad_norm=1.0,\n",
    "    update_interval=512\n",
    ")\n",
    "agent.load(os.path.join(PATH, model_name, \"best\"))\n",
    "\n",
    "all_records = {}\n",
    "for key, phy_react in tqdm(PHY_REACTS.items()):\n",
    "    # Creates the batch envs\n",
    "    env = make_batch_env(test=True, phy_react=phy_react)\n",
    "    scores, lengths, records = batch_run_evaluation_episodes_record_actions(env, agent, n_steps=None, n_episodes=100)\n",
    "    all_records[key] = records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916bbd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(all_records, open(os.path.join(PATH, model_name, \"eval\", \"stats.pkl\"), \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe2f060",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE = False\n",
    "for bleach in PHY_REACTS.keys():\n",
    "\n",
    "    fig, ax = plot_avg_reward(all_records[bleach], ylim=(0, 10))\n",
    "    if SAVE:\n",
    "        savefig(fig, ax, os.path.join(PATH, model_name, \"panels\", f\"{bleach}_avg_reward\"), save_white=True)\n",
    "\n",
    "    figaxes = plot_objs_evolution(all_records[bleach])\n",
    "    if SAVE:\n",
    "        savefig(fig, ax, os.path.join(PATH, model_name, \"panels\", f\"{bleach}_avg_objs_evolution\"), save_white=True)\n",
    "\n",
    "    figaxes = plot_actions_evolution(all_records[bleach])\n",
    "    if SAVE:\n",
    "        savefig(fig, ax, os.path.join(PATH, model_name, \"panels\", f\"{bleach}_avg_actions_evolution\"), save_white=True)    \n",
    "        \n",
    "    example_images = show_acquire_images(all_records[bleach])\n",
    "    for example in example_images:\n",
    "        fig, ax = pyplot.subplots(figsize=(10, 1))\n",
    "        ax.imshow(example[\"sted_image\"], vmin=0, vmax=0.03 * example[\"sted_image\"].max(), cmap=\"hot\")\n",
    "    if SAVE:\n",
    "        for i, example in enumerate(example_images):\n",
    "            io.imsave(os.path.join(PATH, model_name, \"panels\", f\"{bleach}_example-{i}_sted.tif\"), example[\"sted_image\"].astype(numpy.uint16), check_contrast=False)\n",
    "\n",
    "        \n",
    "#     figaxes = plot_last_image(all_records[bleach])\n",
    "#     if SAVE:\n",
    "#         for key, figaxes in figaxes.items():\n",
    "#             if isinstance(figaxes, tuple):\n",
    "#                 fig, ax = figaxes\n",
    "#                 savefig(fig, ax, os.path.join(PATH, model_name, \"panels\", f\"{bleach}_last-images_{key}\"), save_white=True)\n",
    "#             else:\n",
    "#                 for action_name, (fig, ax) in zip(env.actions, figaxes):\n",
    "#                     savefig(fig, ax, os.path.join(PATH, model_name, \"panels\", f\"{bleach}_last-images_{key}_{action_name}\"), save_white=True)            \n",
    "\n",
    "    pyplot.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacf90e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gym-sted",
   "language": "python",
   "name": "gym-sted"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
